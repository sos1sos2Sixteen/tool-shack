# author: shiyao
# created: 2021/9/16

# generic data manipulation
# functions defined in this scope are more easily understood by considering their type signatures.
from itertools import islice
from typing import TypeVar, Callable, Sequence, Iterator, Optional, Dict, List, Tuple

T = TypeVar('T')
E = TypeVar('E')
K = TypeVar('K')
Getter = Callable[[T], K]

def unique_filter(xs : Sequence[T]) -> Iterator[T] : 
    '''
    implement the `Î´` operator in databases.
    removes duplicate items in a sorted iterable of items.

    returns a generator of items
    '''
    last : Optional[T] = None 
    for x in xs : 
        if last != x : 
            yield x
        last = x

def take_every(n: int, xs: Sequence[T]) -> List[T]: 
    '''
    emit every `n` elements from a sequence, starting from the nth element
    '''
    return [x for idx, x in enumerate(xs) if (idx + 1) % n == 0]


def index_by(getter: Getter, xs: Sequence[T]) -> Dict[K, T]: 
    '''
    returns a dict of items indexed by keys.

    prerequisite: keys (as generated by `getter`) in `xs` are unique.
    '''
    return {
        getter(x): x for x in xs
    }

def group_by(getter: Getter, xs: Sequence[T]) -> Dict[K, List[T]]: 
    '''
    returns a dict of list of items indexed by keys. 
    ifferent items with identical keys are grouped together in one entry.
    '''
    res: Dict[K, List[T]] = {}
    for x in xs: 
        k = getter(x)
        if k not in res: 
            res[k] = []
        res[k].append(x)
    return res

def reduce_group(reduction_op: Callable[[Sequence[T]], E], groups: Dict[K, Sequence[T]]) -> Dict[K, E]: 
    '''
    reduce items per group.

    given `groups` a set of sequences indexed by some `key`, 
    and a reduction operation `op` that maps the sequences to some value of type E.
    this function returns the reduced values indexed by `key`.
    '''

    return {
        k: reduction_op(v) for k, v in groups.items()
    }

def map_group(map_op: Callable[[T], E], groups: Dict[K, Sequence[T]]) -> Dict[K, Sequence[E]]: 
    return {
        k : [map_op(t) for t in ts] for k, ts in groups.items()
    }

def big_join(getter_x: Callable[[T], K], getter_y: Callable[[E], K], xs: Sequence[T], ys: Sequence[E]) -> List[Tuple[T, E]]: 
    '''
    mimics the `join` operation in databases.
    given two sets of items `xs` and `ys` 
    and two getter functions to map elemetns in respective collections into a common key type,

    return a list of tuples joining elements of the same keys together.
    '''

    x_indexed = index_by(getter_x, xs)
    y_indexed = index_by(getter_y, ys)
    x_ks = set(x_indexed.keys())
    y_ks = set(y_indexed.keys())
    common_ks = x_ks.intersection(y_ks)
    return [
        (x_indexed[k], y_indexed[k])
        for k in common_ks
    ]

def align_table(xss : Sequence[Sequence[T]], serializer: Callable[[T], str] = str) -> str : 
    '''
    return a list of list of data as a HTML table

    @param xss : Sequence of sequence of objects (serializable)
    @param serializer : a callable that converts input element type into readable strings.

    @returns html code as string
    '''
    rows = []
    for xs in xss : 
        row = f"<tr>{''.join([f'<td>{serializer(x)}</td>' for x in xs])}</tr>"
        rows.append(row)
    return f"<table>{''.join(rows)}</table>"

def _not_comment(line: str) -> bool: 
    import re
    # this line is protected by re.compile's internal caching
    _comment_pattern = re.compile(r'([\s]*#[\s\S]*$)|(^$)')
    return _comment_pattern.match(line) is None

def comment_guard(xs: Iterator[str]) -> Iterator[str]: 
    '''
    filter out comment lines of a "file"

    `comment line` is (after trimming) a line that starts with a hashtag (`#`), as is in python
    '''
    return filter(_not_comment, xs)

def gen_disjoint_indices(population: int, max_try: int = 3) -> Iterator[int]: 
    '''
    generate (most probably) disjoint indices within the range of [0, population).

    want to achieve the effect of:
    ```python
    xs = [idx for idx in range(population)]
    random.shuffle(xs)
    for x in xs: 
        yield x
    ```
    but memory friendly if `population` is large.
    '''

    # TODO[improve]: need better implementations
    import random
    seen = set()
    while True: 
        candidate = random.randint(0, population - 1)
        for _ in range(max_try): 
            if candidate not in seen: 
                seen.add(candidate)
                break
            candidate = random.randint(0, population - 1)
        yield candidate

def window(seq, n=2):
    "Returns a sliding window (of width n) over data from the iterable"
    "   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   "
    it = iter(seq)
    result = tuple(islice(it, n))
    if len(result) == n:
        yield result
    for elem in it:
        result = result[1:] + (elem,)
        yield result

def chunk(iterable: Iterator[T], chunk_size: int) -> Iterator[T]:
    '''chunk([4, 2, 3, 1], 3) -> [[4, 2, 3], [1]]
    
    note: last batch kept.
    '''
    ret = []
    for record in iterable:
        ret.append(record)
        if len(ret) == chunk_size:
            yield ret
            ret = []
    if ret:
        yield ret

def find(target: T, xs: Sequence[T], key: Callable[[T], K] = lambda x: x) -> Optional[T]: 
    '''linear search on iterable
    
    returns the target element in `xs`, returns None if not found.
    '''
    for x in xs: 
        if key(x) == target: return x
    return None

def apply_function(x, op, predicate):
    if isinstance(x, (list, tuple)):
        return type(x)(apply_function(item, op, predicate) for item in x)
    elif isinstance(x, dict):
        return {k: apply_function(v, op, predicate) for k, v in x.items()}
    elif predicate(x):
        return op(x)
    else:
        return x
